NLTK - Natural Language Tool Kit package for Python
nltk.tokenize tokenize module
Tokenizers divide strings into lists of substrings. For example, tokenizers can be used to find the list of sentences or words in a string.

nltk_lite.wordnet
  which incorporates pywordnet and which supports WordNet 2.1. It is included in NLTK Lite.

from nltk.corpus import wordnet

MongoDB
#Activate MongoDB daemon
$mongod

PyMongo
>>> import pymongo


Python Twitter Tools

Working with tweets

>>>from twitter import *
>>>twitter = Twitter(domain="search.twitter.com")
>>>t = twitter.search(format="json", q="#gaza", lang="en")
>>>t[u'results'] #list of tweets

import unicodedata

In [27]: unicodedata.normalize('NFKD', a_tweet[u'text']).encode('ascii','ignore')
